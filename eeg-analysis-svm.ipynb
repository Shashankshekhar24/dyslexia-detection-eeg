{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./EEG_data.csv')\n",
    "data = pd.read_csv('./demographic_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>VideoID</th>\n",
       "      <th>Attention</th>\n",
       "      <th>Mediation</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>Gamma2</th>\n",
       "      <th>predefinedlabel</th>\n",
       "      <th>user-definedlabeln</th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>25354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2012240.0</td>\n",
       "      <td>129350.0</td>\n",
       "      <td>61236.0</td>\n",
       "      <td>17084.0</td>\n",
       "      <td>11488.0</td>\n",
       "      <td>62462.0</td>\n",
       "      <td>49960.0</td>\n",
       "      <td>33932.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1005145.0</td>\n",
       "      <td>354328.0</td>\n",
       "      <td>37102.0</td>\n",
       "      <td>88881.0</td>\n",
       "      <td>45307.0</td>\n",
       "      <td>99603.0</td>\n",
       "      <td>44790.0</td>\n",
       "      <td>29749.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SubjectID  VideoID  Attention  Mediation    Raw      Delta     Theta  \\\n",
       "0        0.0      0.0       56.0       43.0  278.0   301963.0   90612.0   \n",
       "1        0.0      0.0       40.0       35.0  -50.0    73787.0   28083.0   \n",
       "2        0.0      0.0       47.0       48.0  101.0   758353.0  383745.0   \n",
       "3        0.0      0.0       47.0       57.0   -5.0  2012240.0  129350.0   \n",
       "4        0.0      0.0       44.0       53.0   -8.0  1005145.0  354328.0   \n",
       "\n",
       "     Alpha1   Alpha2    Beta1     Beta2   Gamma1   Gamma2  predefinedlabel  \\\n",
       "0   33735.0  23991.0  27946.0   45097.0  33228.0   8293.0              0.0   \n",
       "1    1439.0   2240.0   2746.0    3687.0   5293.0   2740.0              0.0   \n",
       "2  201999.0  62107.0  36293.0  130536.0  57243.0  25354.0              0.0   \n",
       "3   61236.0  17084.0  11488.0   62462.0  49960.0  33932.0              0.0   \n",
       "4   37102.0  88881.0  45307.0   99603.0  44790.0  29749.0              0.0   \n",
       "\n",
       "   user-definedlabeln  age    ethnicity gender  \n",
       "0                 0.0   25  Han Chinese      M  \n",
       "1                 0.0   25  Han Chinese      M  \n",
       "2                 0.0   25  Han Chinese      M  \n",
       "3                 0.0   25  Han Chinese      M  \n",
       "4                 0.0   25  Han Chinese      M  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.rename(columns = {'subject ID': 'SubjectID',' gender':'gender',' age':'age',' ethnicity':'ethnicity'})\n",
    "df = df.merge(data,how = 'inner',on = 'SubjectID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12811, 18)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12811 entries, 0 to 12810\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   SubjectID           12811 non-null  float64\n",
      " 1   VideoID             12811 non-null  float64\n",
      " 2   Attention           12811 non-null  float64\n",
      " 3   Mediation           12811 non-null  float64\n",
      " 4   Raw                 12811 non-null  float64\n",
      " 5   Delta               12811 non-null  float64\n",
      " 6   Theta               12811 non-null  float64\n",
      " 7   Alpha1              12811 non-null  float64\n",
      " 8   Alpha2              12811 non-null  float64\n",
      " 9   Beta1               12811 non-null  float64\n",
      " 10  Beta2               12811 non-null  float64\n",
      " 11  Gamma1              12811 non-null  float64\n",
      " 12  Gamma2              12811 non-null  float64\n",
      " 13  predefinedlabel     12811 non-null  float64\n",
      " 14  user-definedlabeln  12811 non-null  float64\n",
      " 15  age                 12811 non-null  int64  \n",
      " 16  ethnicity           12811 non-null  object \n",
      " 17  gender              12811 non-null  object \n",
      "dtypes: float64(15), int64(1), object(2)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SubjectID', 'VideoID', 'Attention', 'Mediation', 'Raw', 'Delta',\n",
       "       'Theta', 'Alpha1', 'Alpha2', 'Beta1', 'Beta2', 'Gamma1', 'Gamma2',\n",
       "       'predefinedlabel', 'user-definedlabeln', 'age', 'ethnicity', 'gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender']=df['gender'].replace({'M':1,'F':0})\n",
    "df['ethnicity']=df['ethnicity'].replace({'Han Chinese':0,'Bengali':1,'English':2})\n",
    "df.drop(columns = ['SubjectID','VideoID','predefinedlabel'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attention</th>\n",
       "      <th>Mediation</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>Gamma2</th>\n",
       "      <th>user-definedlabeln</th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>25354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2012240.0</td>\n",
       "      <td>129350.0</td>\n",
       "      <td>61236.0</td>\n",
       "      <td>17084.0</td>\n",
       "      <td>11488.0</td>\n",
       "      <td>62462.0</td>\n",
       "      <td>49960.0</td>\n",
       "      <td>33932.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1005145.0</td>\n",
       "      <td>354328.0</td>\n",
       "      <td>37102.0</td>\n",
       "      <td>88881.0</td>\n",
       "      <td>45307.0</td>\n",
       "      <td>99603.0</td>\n",
       "      <td>44790.0</td>\n",
       "      <td>29749.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attention  Mediation    Raw      Delta     Theta    Alpha1   Alpha2  \\\n",
       "0       56.0       43.0  278.0   301963.0   90612.0   33735.0  23991.0   \n",
       "1       40.0       35.0  -50.0    73787.0   28083.0    1439.0   2240.0   \n",
       "2       47.0       48.0  101.0   758353.0  383745.0  201999.0  62107.0   \n",
       "3       47.0       57.0   -5.0  2012240.0  129350.0   61236.0  17084.0   \n",
       "4       44.0       53.0   -8.0  1005145.0  354328.0   37102.0  88881.0   \n",
       "\n",
       "     Beta1     Beta2   Gamma1   Gamma2  user-definedlabeln  age  ethnicity  \\\n",
       "0  27946.0   45097.0  33228.0   8293.0                 0.0   25          0   \n",
       "1   2746.0    3687.0   5293.0   2740.0                 0.0   25          0   \n",
       "2  36293.0  130536.0  57243.0  25354.0                 0.0   25          0   \n",
       "3  11488.0   62462.0  49960.0  33932.0                 0.0   25          0   \n",
       "4  45307.0   99603.0  44790.0  29749.0                 0.0   25          0   \n",
       "\n",
       "   gender  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is for checking null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if(df[col].isnull().sum()>0):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fea=df.drop(['user-definedlabeln'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attention</th>\n",
       "      <th>Mediation</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>Gamma2</th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>25354.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2012240.0</td>\n",
       "      <td>129350.0</td>\n",
       "      <td>61236.0</td>\n",
       "      <td>17084.0</td>\n",
       "      <td>11488.0</td>\n",
       "      <td>62462.0</td>\n",
       "      <td>49960.0</td>\n",
       "      <td>33932.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1005145.0</td>\n",
       "      <td>354328.0</td>\n",
       "      <td>37102.0</td>\n",
       "      <td>88881.0</td>\n",
       "      <td>45307.0</td>\n",
       "      <td>99603.0</td>\n",
       "      <td>44790.0</td>\n",
       "      <td>29749.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attention  Mediation    Raw      Delta     Theta    Alpha1   Alpha2  \\\n",
       "0       56.0       43.0  278.0   301963.0   90612.0   33735.0  23991.0   \n",
       "1       40.0       35.0  -50.0    73787.0   28083.0    1439.0   2240.0   \n",
       "2       47.0       48.0  101.0   758353.0  383745.0  201999.0  62107.0   \n",
       "3       47.0       57.0   -5.0  2012240.0  129350.0   61236.0  17084.0   \n",
       "4       44.0       53.0   -8.0  1005145.0  354328.0   37102.0  88881.0   \n",
       "\n",
       "     Beta1     Beta2   Gamma1   Gamma2  age  ethnicity  gender  \n",
       "0  27946.0   45097.0  33228.0   8293.0   25          0       1  \n",
       "1   2746.0    3687.0   5293.0   2740.0   25          0       1  \n",
       "2  36293.0  130536.0  57243.0  25354.0   25          0       1  \n",
       "3  11488.0   62462.0  49960.0  33932.0   25          0       1  \n",
       "4  45307.0   99603.0  44790.0  29749.0   25          0       1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_fea.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=df['user-definedlabeln']\n",
    "X_train,x_test,Y_train,y_test=train_test_split(top_fea,y,random_state=108,test_size=0.27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=108)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=108)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(random_state=108)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(random_state=108)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = svm_classifier.predict(x_test).astype(int)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5935241399248338"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='g', vmin=0, cbar=False)\n",
    "\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 17:23:24.951102: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks,layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "234/234 [==============================] - 3s 12ms/step - loss: 2859.8762 - accuracy: 0.5021 - auc: 0.5000 - val_loss: 3456.0056 - val_accuracy: 0.5174 - val_auc: 0.5003 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 1754.5132 - accuracy: 0.5050 - auc: 0.5027 - val_loss: 335.4247 - val_accuracy: 0.4987 - val_auc: 0.4969 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 1220.3165 - accuracy: 0.5054 - auc: 0.5037 - val_loss: 821.5207 - val_accuracy: 0.4960 - val_auc: 0.4973 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "234/234 [==============================] - 3s 13ms/step - loss: 910.3136 - accuracy: 0.5146 - auc: 0.5134 - val_loss: 310.6754 - val_accuracy: 0.5291 - val_auc: 0.5229 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "234/234 [==============================] - 3s 12ms/step - loss: 897.8929 - accuracy: 0.5221 - auc: 0.5206 - val_loss: 1330.0424 - val_accuracy: 0.4885 - val_auc: 0.5068 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "234/234 [==============================] - 3s 11ms/step - loss: 513.1543 - accuracy: 0.5283 - auc: 0.5268 - val_loss: 158.0826 - val_accuracy: 0.5575 - val_auc: 0.5474 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "234/234 [==============================] - 3s 11ms/step - loss: 354.6418 - accuracy: 0.5237 - auc: 0.5222 - val_loss: 162.2288 - val_accuracy: 0.5500 - val_auc: 0.5426 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "234/234 [==============================] - 4s 17ms/step - loss: 479.0825 - accuracy: 0.5320 - auc: 0.5316 - val_loss: 224.0659 - val_accuracy: 0.5489 - val_auc: 0.5380 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 325.5753 - accuracy: 0.5240 - auc: 0.5230 - val_loss: 164.7961 - val_accuracy: 0.5045 - val_auc: 0.5202 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 303.2897 - accuracy: 0.5291 - auc: 0.5274 - val_loss: 409.6920 - val_accuracy: 0.4880 - val_auc: 0.5059 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 294.7046 - accuracy: 0.5285 - auc: 0.5289 - val_loss: 603.0310 - val_accuracy: 0.5265 - val_auc: 0.5130 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 273.0593 - accuracy: 0.5313 - auc: 0.5303 - val_loss: 121.5164 - val_accuracy: 0.5056 - val_auc: 0.5093 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 175.2305 - accuracy: 0.5324 - auc: 0.5324 - val_loss: 241.3547 - val_accuracy: 0.5355 - val_auc: 0.5254 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "234/234 [==============================] - 3s 14ms/step - loss: 189.8327 - accuracy: 0.5288 - auc: 0.5288 - val_loss: 114.5506 - val_accuracy: 0.5462 - val_auc: 0.5396 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "234/234 [==============================] - 3s 11ms/step - loss: 203.0302 - accuracy: 0.5213 - auc: 0.5216 - val_loss: 60.0198 - val_accuracy: 0.5425 - val_auc: 0.5360 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 125.6413 - accuracy: 0.5423 - auc: 0.5415 - val_loss: 192.9512 - val_accuracy: 0.5430 - val_auc: 0.5387 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 128.5155 - accuracy: 0.5416 - auc: 0.5415 - val_loss: 78.4104 - val_accuracy: 0.5494 - val_auc: 0.5454 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 95.7249 - accuracy: 0.5359 - auc: 0.5359 - val_loss: 65.6832 - val_accuracy: 0.5452 - val_auc: 0.5491 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 82.7237 - accuracy: 0.5521 - auc: 0.5519 - val_loss: 109.6378 - val_accuracy: 0.5387 - val_auc: 0.5309 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 145.6003 - accuracy: 0.5324 - auc: 0.5324 - val_loss: 173.7102 - val_accuracy: 0.4992 - val_auc: 0.5108 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 71.2369 - accuracy: 0.5334 - auc: 0.5357 - val_loss: 38.7585 - val_accuracy: 0.5120 - val_auc: 0.5141 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 55.5001 - accuracy: 0.5402 - auc: 0.5409 - val_loss: 38.4528 - val_accuracy: 0.5019 - val_auc: 0.5151 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 69.4894 - accuracy: 0.5364 - auc: 0.5391 - val_loss: 82.0125 - val_accuracy: 0.5526 - val_auc: 0.5494 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 39.5060 - accuracy: 0.5451 - auc: 0.5514 - val_loss: 61.0025 - val_accuracy: 0.5468 - val_auc: 0.5416 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 42.1839 - accuracy: 0.5438 - auc: 0.5462 - val_loss: 48.9956 - val_accuracy: 0.5094 - val_auc: 0.5268 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 36.3870 - accuracy: 0.5469 - auc: 0.5516 - val_loss: 20.5035 - val_accuracy: 0.5548 - val_auc: 0.5580 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 29.3102 - accuracy: 0.5521 - auc: 0.5534 - val_loss: 16.1966 - val_accuracy: 0.5500 - val_auc: 0.5418 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 24.8183 - accuracy: 0.5521 - auc: 0.5561 - val_loss: 36.4628 - val_accuracy: 0.5575 - val_auc: 0.5564 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 24.6580 - accuracy: 0.5628 - auc: 0.5649 - val_loss: 14.1049 - val_accuracy: 0.5200 - val_auc: 0.5319 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 18.1256 - accuracy: 0.5430 - auc: 0.5486 - val_loss: 56.1357 - val_accuracy: 0.4971 - val_auc: 0.5027 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 24.7424 - accuracy: 0.5549 - auc: 0.5635 - val_loss: 53.5717 - val_accuracy: 0.5452 - val_auc: 0.5408 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 17.8433 - accuracy: 0.5490 - auc: 0.5582 - val_loss: 20.1871 - val_accuracy: 0.5580 - val_auc: 0.5635 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 20.2583 - accuracy: 0.5579 - auc: 0.5613 - val_loss: 31.9014 - val_accuracy: 0.5425 - val_auc: 0.5417 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 16.6484 - accuracy: 0.5503 - auc: 0.5526 - val_loss: 8.9336 - val_accuracy: 0.5484 - val_auc: 0.5606 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 13.3738 - accuracy: 0.5503 - auc: 0.5552 - val_loss: 25.2369 - val_accuracy: 0.5227 - val_auc: 0.5165 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 12.1523 - accuracy: 0.5399 - auc: 0.5494 - val_loss: 10.5506 - val_accuracy: 0.5083 - val_auc: 0.5118 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 11.9138 - accuracy: 0.5370 - auc: 0.5433 - val_loss: 8.8997 - val_accuracy: 0.5430 - val_auc: 0.5574 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 9.7640 - accuracy: 0.5372 - auc: 0.5458 - val_loss: 9.3305 - val_accuracy: 0.5494 - val_auc: 0.5547 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 8.9461 - accuracy: 0.5494 - auc: 0.5606 - val_loss: 14.2318 - val_accuracy: 0.4917 - val_auc: 0.4989 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 7.9831 - accuracy: 0.5402 - auc: 0.5473 - val_loss: 12.1859 - val_accuracy: 0.5510 - val_auc: 0.5647 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 6.4701 - accuracy: 0.5446 - auc: 0.5527 - val_loss: 3.9459 - val_accuracy: 0.5628 - val_auc: 0.5785 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 4.6179 - accuracy: 0.5448 - auc: 0.5512 - val_loss: 7.8764 - val_accuracy: 0.4917 - val_auc: 0.4803 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 5.4166 - accuracy: 0.5514 - auc: 0.5550 - val_loss: 5.0151 - val_accuracy: 0.4885 - val_auc: 0.4787 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 3.2800 - accuracy: 0.5562 - auc: 0.5747 - val_loss: 3.9253 - val_accuracy: 0.5029 - val_auc: 0.4833 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 2.9166 - accuracy: 0.5525 - auc: 0.5647 - val_loss: 2.8787 - val_accuracy: 0.5628 - val_auc: 0.5883 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 2.7333 - accuracy: 0.5570 - auc: 0.5743 - val_loss: 3.2982 - val_accuracy: 0.5532 - val_auc: 0.5729 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 2.8598 - accuracy: 0.5494 - auc: 0.5620 - val_loss: 2.1211 - val_accuracy: 0.5521 - val_auc: 0.5848 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 2.2507 - accuracy: 0.5539 - auc: 0.5677 - val_loss: 2.8401 - val_accuracy: 0.5334 - val_auc: 0.5690 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 2.3530 - accuracy: 0.5450 - auc: 0.5576 - val_loss: 2.7090 - val_accuracy: 0.5516 - val_auc: 0.5801 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 1.5554 - accuracy: 0.5525 - auc: 0.5688 - val_loss: 1.6453 - val_accuracy: 0.4933 - val_auc: 0.5020 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(X_train.shape[1]))\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model=tf.keras.Model(inputs,outputs)\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy',tf.keras.metrics.AUC(name='auc')]\n",
    "             )\n",
    "batch_size=32\n",
    "epochs=50\n",
    "history=model.fit(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            validation_split=0.2,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=[tf.keras.callbacks.ReduceLROnPlateau()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20331/295032384.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_pred = np.array(y_pred >=0.5, dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array(y_test)\n",
    "\n",
    "y_pred = np.squeeze(model.predict(x_test))\n",
    "y_pred = np.array(y_pred >=0.5, dtype=np.int)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.511130384504192"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracyKeras=accuracy_score(y_true, y_pred)\n",
    "accuracyKeras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
