{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle Component Analysis\n",
    "\n",
    "- pca is a dimensionality reduction technique that can be used to reduce the number of dimensions (features) in a dataset while retaining as much information as possible.\n",
    "- This is done by finding a new set of features that are linear combinations of the original features. The new features are called principle components (PCs).\n",
    "- The first PC is the linear combination of the original features that has the largest variance.\n",
    "- The second PC is the linear combination of the original features that has the second largest variance and is orthogonal to the first PC.\n",
    "- The third PC is the linear combination of the original features that has the third largest variance and is orthogonal to the first two PCs.\n",
    "This process continues until all of the variance in the original features is accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2d example:\n",
    "| x | y |\n",
    "|---|---|\n",
    "| 1 | 2 |\n",
    "| 3 | 4 |\n",
    "| 5 | 6 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1, 2],\n",
    "                 [3, 4],\n",
    "                 [5, 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of x and y:\n",
    "$\\bar{X}=\\frac{x_1+x_2+x_3+\\ldots+x_n}{n}$\n",
    "$\\bar{y}=\\frac{y_1+y_2+y_3+\\ldots+y_n}{n}$\n",
    "\n",
    "The formula for calculating the standard deviation $\\sigma$ is given by:\n",
    "\n",
    "$\\sigma_x = \\sqrt{\\frac{\\sum_{i=1}^{N}(X_i - \\bar{X})^2}{N}}$\n",
    "\n",
    "Where:\n",
    "- $N$ is the number of data points,\n",
    "- $X_i$ represents each individual data point,\n",
    "- $\\bar{X}$ is the mean of the data set.\n",
    "\n",
    "then standardize ($Z$) the data by this formula:\n",
    "\n",
    "$Z = \\frac{X_i - \\mu_x}{\\sigma_x}$\n",
    "\n",
    "Where:\n",
    "- $X_i$ represents each individual data point,\n",
    "- $ \\mu_x $ is the mean of the data set,\n",
    "- $ \\sigma_x $ is the standard deviation of the data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 4.]\n",
      "[1.63299316 1.63299316]\n",
      "[[-1.22474487  0.          1.22474487]\n",
      " [-1.22474487  0.          1.22474487]]\n",
      "[[-1.22474487 -1.22474487]\n",
      " [ 0.          0.        ]\n",
      " [ 1.22474487  1.22474487]]\n"
     ]
    }
   ],
   "source": [
    "mean = data.mean(axis=0)\n",
    "std_dev = data.std(axis=0)\n",
    "standardized_data = (data - mean) / std_dev\n",
    "transposed_data = standardized_data.T\n",
    "print(mean)\n",
    "print(std_dev)\n",
    "print(transposed_data)\n",
    "print(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_mean=standardized_data.mean(axis=0)\n",
    "std_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the covariance matrix for a set of variables (X, Y), you can use the following steps:\n",
    "\n",
    "1. Calculate the mean ($ \\bar{X}, \\bar{Y} $) for each variable.\n",
    "\n",
    "2. For each pair of variables, compute the covariance ($Cov(X, Y)$) using the formula:\n",
    "\n",
    "$ Cov(X, Y) = \\frac{\\sum_{i=1}^{N}(X_i - \\bar{X})(Y_i - \\bar{Y})}{N-1} $\n",
    "\n",
    "3. Assemble the covariance values into a matrix:\n",
    "\n",
    "$ \n",
    "\\text{Covariance Matrix} = \n",
    "\\begin{bmatrix}\n",
    "    Cov(X, X) & Cov(X, Y) \\\\\n",
    "    Cov(Y, X) & Cov(Y, Y) \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "This matrix represents the covariance relationships between the variables X and Y.<br>\n",
    "**In my case i used standardized_data to calculate covariance_matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5, 1.5],\n",
       "       [1.5, 1.5]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance_matrix = np.cov(standardized_data, rowvar=False)\n",
    "covariance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the eigenvalues of a covariance matrix, you can follow these steps:\n",
    "\n",
    "1. Formulate and calculate the covariance matrix ($C$) based on your data.\n",
    "\n",
    "2. Use the determinant equation to find the characteristic equation:\n",
    "\n",
    "$ \\text{det}(C - \\lambda I) = 0 $\n",
    "\n",
    "Where:\n",
    "- $C$ is the covariance matrix,\n",
    "- $\\lambda$ represents the eigenvalue,\n",
    "- $I$ is the identity matrix.\n",
    "\n",
    "3. Solve the characteristic equation for $\\lambda$ to find the eigenvalues.\n",
    "\n",
    "The resulting eigenvalues ($\\lambda_1, \\lambda_2, \\ldots, \\lambda_n$) represent the variances along the principal components of the data.\n",
    "\n",
    "To calculate the eigenvectors corresponding to the eigenvalues ($\\lambda_1, \\lambda_2, \\ldots, \\lambda_n$) of a covariance matrix, follow these steps:\n",
    "\n",
    "4. Substitute each eigenvalue back into the equation $(C - \\lambda I) \\mathbf{v} = \\mathbf{0}$ to solve for the corresponding eigenvector ($\\mathbf{v}$).\n",
    "\n",
    "   For each eigenvalue $\\lambda_i$:\n",
    "   \n",
    "   $ (C - \\lambda_i I) \\mathbf{v_i} = \\mathbf{0} $<br>\n",
    "   $ C\\mathbf{v_i} - \\lambda_i\\mathbf{v_i} = \\mathbf{0}$\n",
    "\n",
    "   Where:\n",
    "   - $C$ is the covariance matrix,\n",
    "   - $\\lambda_i$ is the i-th eigenvalue,\n",
    "   - $\\mathbf{v_i}$ is the i-th eigenvector.\n",
    "\n",
    "5. The solutions to the above equations will give you the eigenvectors corresponding to each eigenvalue.\n",
    "\n",
    "The resulting eigenvectors ($\\mathbf{v_1, v_2, \\ldots, v_n}$) represent the directions along which the data varies the most.\n",
    "\n",
    "6. To normalize the eigenvector $\\mathbf{v_i}$, you can use the following equation:\n",
    "\n",
    "$ \\mathbf{v_{i, \\text{normalized}}} = \\frac{\\mathbf{v_i}}{\\sqrt{\\sum_{j=1}^{n} (v_{i_j})^2}} $\n",
    "\n",
    "Where:\n",
    "- $\\mathbf{v_{i, \\text{normalized}}}$ is the normalized eigenvector,\n",
    "- $\\mathbf{v_i}$ is the original eigenvector,\n",
    "- $\\sqrt{\\sum_{j=1}^{n} (v_{i_j})^2}$ is the Euclidean norm (L2 norm) of the eigenvector.\n",
    "\n",
    "7. The reduced data matrix $Y$ is calculated by multiplying the original data matrix $Z$ with the matrix of eigenvectors $V$:\n",
    "\n",
    "$ Y = Z \\cdot V $\n",
    "\n",
    "Where:\n",
    "- $Y$ is the reduced data matrix,(reduced_data)\n",
    "- $Z$ is the original data matrix,(standardized_data)\n",
    "- $V$ is the matrix of eigenvectors.(normalized eigenvectors)\n",
    "\n",
    "This transformation allows you to project the original data onto the principal components represented by the eigenvectors.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_components = pca.components_\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_explained_variance = np.cumsum(explained_variance)\n",
    "threshold = 0.95\n",
    "n_components = np.argmax(cumulative_explained_variance >= threshold) + 1\n",
    "n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = pca.transform(standardized_data)[:, :n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "Standardized Data:\n",
      " [[-1.22474487 -1.22474487]\n",
      " [ 0.          0.        ]\n",
      " [ 1.22474487  1.22474487]]\n",
      "\n",
      "Principal Components:\n",
      " [[-0.70710678 -0.70710678]\n",
      " [-0.70710678  0.70710678]]\n",
      "\n",
      "Explained Variance:\n",
      " [1. 0.]\n",
      "\n",
      "Cumulative Explained Variance:\n",
      " [1. 1.]\n",
      "\n",
      "Reduced Data (1 Components):\n",
      " [[ 1.73205081]\n",
      " [ 0.        ]\n",
      " [-1.73205081]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Data:\\n\", data)\n",
    "print(\"\\nStandardized Data:\\n\", standardized_data)\n",
    "print(\"\\nPrincipal Components:\\n\", principal_components)\n",
    "print(\"\\nExplained Variance:\\n\", explained_variance)\n",
    "print(\"\\nCumulative Explained Variance:\\n\", cumulative_explained_variance)\n",
    "print(\"\\nReduced Data ({} Components):\\n\".format(n_components), reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.82842712],\n",
       "       [ 0.        ],\n",
       "       [ 2.82842712]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=PCA(n_components=1)\n",
    "pc1=pca.fit_transform(data)\n",
    "pc1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
