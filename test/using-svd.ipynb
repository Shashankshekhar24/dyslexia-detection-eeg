{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.linalg import svd\n",
    "from numpy import array\n",
    "from numpy import diag\n",
    "from numpy import dot\n",
    "from numpy import zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./EEG_data.csv')\n",
    "data = pd.read_csv('./demographic_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>VideoID</th>\n",
       "      <th>Attention</th>\n",
       "      <th>Mediation</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>Gamma2</th>\n",
       "      <th>predefinedlabel</th>\n",
       "      <th>user-definedlabeln</th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>25354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2012240.0</td>\n",
       "      <td>129350.0</td>\n",
       "      <td>61236.0</td>\n",
       "      <td>17084.0</td>\n",
       "      <td>11488.0</td>\n",
       "      <td>62462.0</td>\n",
       "      <td>49960.0</td>\n",
       "      <td>33932.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1005145.0</td>\n",
       "      <td>354328.0</td>\n",
       "      <td>37102.0</td>\n",
       "      <td>88881.0</td>\n",
       "      <td>45307.0</td>\n",
       "      <td>99603.0</td>\n",
       "      <td>44790.0</td>\n",
       "      <td>29749.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SubjectID  VideoID  Attention  Mediation    Raw      Delta     Theta  \\\n",
       "0        0.0      0.0       56.0       43.0  278.0   301963.0   90612.0   \n",
       "1        0.0      0.0       40.0       35.0  -50.0    73787.0   28083.0   \n",
       "2        0.0      0.0       47.0       48.0  101.0   758353.0  383745.0   \n",
       "3        0.0      0.0       47.0       57.0   -5.0  2012240.0  129350.0   \n",
       "4        0.0      0.0       44.0       53.0   -8.0  1005145.0  354328.0   \n",
       "\n",
       "     Alpha1   Alpha2    Beta1     Beta2   Gamma1   Gamma2  predefinedlabel  \\\n",
       "0   33735.0  23991.0  27946.0   45097.0  33228.0   8293.0              0.0   \n",
       "1    1439.0   2240.0   2746.0    3687.0   5293.0   2740.0              0.0   \n",
       "2  201999.0  62107.0  36293.0  130536.0  57243.0  25354.0              0.0   \n",
       "3   61236.0  17084.0  11488.0   62462.0  49960.0  33932.0              0.0   \n",
       "4   37102.0  88881.0  45307.0   99603.0  44790.0  29749.0              0.0   \n",
       "\n",
       "   user-definedlabeln  age    ethnicity gender  \n",
       "0                 0.0   25  Han Chinese      M  \n",
       "1                 0.0   25  Han Chinese      M  \n",
       "2                 0.0   25  Han Chinese      M  \n",
       "3                 0.0   25  Han Chinese      M  \n",
       "4                 0.0   25  Han Chinese      M  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.rename(columns = {'subject ID': 'SubjectID',' gender':'gender',' age':'age',' ethnicity':'ethnicity'})\n",
    "df = df.merge(data,how = 'inner',on = 'SubjectID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender']=df['gender'].replace({'M':1,'F':0})\n",
    "df['ethnicity']=df['ethnicity'].replace({'Han Chinese':0,'Bengali':1,'English':2})\n",
    "df.drop(columns = ['SubjectID','VideoID','predefinedlabel'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fea=df.drop(['user-definedlabeln'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12811, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_fea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SVD\n",
    "U, s, Vt = svd(top_fea)\n",
    "\n",
    "# U, Sigma, and Vt are the matrices such that X = U * Sigma * Vt\n",
    "# U: left singular vectors\n",
    "# Sigma: singular values\n",
    "# Vt: right singular vectors (transposed)\n",
    "\n",
    "# Print the results\n",
    "# print(\"Matrix U:\")\n",
    "# print(U)\n",
    "# print(\"\\nMatrix Sigma:\")\n",
    "# print(np.diag(Sigma))  # Convert singular values to a diagonal matrix for clarity\n",
    "# print(\"\\nMatrix Vt:\")\n",
    "# print(Vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.02815735e+08, 2.47419719e+07, 1.17474564e+07, 6.78210125e+06,\n",
       "       4.69828671e+06, 3.86504995e+06, 3.02495082e+06, 2.33043954e+06,\n",
       "       6.60638244e+04, 6.60396203e+03, 1.69448609e+03, 8.88673211e+02,\n",
       "       6.47587588e+01, 4.52827000e+01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102815734.97584194\n",
      "24741971.882308476\n",
      "11747456.442044646\n",
      "6782101.250381863\n",
      "4698286.706368632\n",
      "3865049.9485918744\n",
      "3024950.821600757\n",
      "2330439.5382966707\n",
      "66063.82436054252\n",
      "6603.962025051184\n",
      "1694.4860899795544\n",
      "888.6732111679671\n",
      "64.75875879514957\n",
      "45.282699976007116\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,14):\n",
    "    print(s[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160081352.55258036"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6422717782951707\n",
      "0.15455873834013067\n",
      "0.07338429026695083\n",
      "0.04236659137518352\n",
      "0.02934936912670969\n",
      "0.02414428593313115\n",
      "0.018896334728351206\n",
      "0.014557845127721632\n",
      "0.00041268906907094747\n",
      "4.125378702608129e-05\n",
      "1.0585156003245183e-05\n",
      "5.551384948950086e-06\n",
      "4.0453655446145046e-07\n",
      "2.828730470723225e-07\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,14):\n",
    "    print(s[i]/s.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12811, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma = zeros((top_fea.shape[0], top_fea.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12811, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma[:top_fea.shape[1], :top_fea.shape[1]] = diag(s)\n",
    "Sigma.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_elements = 1\n",
    "Sigma = Sigma[:, :n_elements]\n",
    "\n",
    "Vt = Vt[:n_elements, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed Matrix:\n",
      "[[8.77049378e+00 1.08767932e+01 2.42723728e+01 ... 6.12931164e+00\n",
      "  1.84488537e-02 1.79385242e-01]\n",
      " [2.15036547e+00 2.66679176e+00 5.95114411e+00 ... 1.50279567e+00\n",
      "  4.52332318e-03 4.39819969e-02]\n",
      " [2.31933661e+01 2.87634257e+01 6.41877234e+01 ... 1.62088216e+01\n",
      "  4.87875628e-02 4.74380085e-01]\n",
      " ...\n",
      " [1.91720724e+01 2.37763885e+01 5.30587789e+01 ... 1.33985166e+01\n",
      "  4.03287166e-02 3.92131497e-01]\n",
      " [9.90568711e+00 1.22846117e+01 2.74140244e+01 ... 6.92264824e+00\n",
      "  2.08367484e-02 2.02603653e-01]\n",
      " [3.92750299e+01 4.87072209e+01 1.08693785e+02 ... 2.74475878e+01\n",
      "  8.26155627e-02 8.03302633e-01]]\n"
     ]
    }
   ],
   "source": [
    "B = U.dot(Sigma.dot(Vt))\n",
    "print(\"Reconstructed Matrix:\")\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12811, 14)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X=scaler.fit_transform(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=df['user-definedlabeln']\n",
    "X_train,x_test,Y_train,y_test=train_test_split(X,y,random_state=108,test_size=0.27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=108)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=108)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(random_state=108)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(random_state=108)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svm_classifier.predict(x_test).astype(int)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5883203237930038"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 23:26:38.810564: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks,layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 23:26:56.149098: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "234/234 [==============================] - 3s 11ms/step - loss: 0.6842 - accuracy: 0.5756 - auc: 0.5878 - val_loss: 0.6842 - val_accuracy: 0.5671 - val_auc: 0.5715 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.6808 - accuracy: 0.5793 - auc: 0.5893 - val_loss: 0.6817 - val_accuracy: 0.5655 - val_auc: 0.5894 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.6814 - accuracy: 0.5747 - auc: 0.5880 - val_loss: 0.6808 - val_accuracy: 0.5655 - val_auc: 0.5874 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6791 - accuracy: 0.5813 - auc: 0.5943 - val_loss: 0.6857 - val_accuracy: 0.5623 - val_auc: 0.5874 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "234/234 [==============================] - 3s 13ms/step - loss: 0.6783 - accuracy: 0.5787 - auc: 0.5952 - val_loss: 0.6831 - val_accuracy: 0.5617 - val_auc: 0.5862 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "234/234 [==============================] - 3s 11ms/step - loss: 0.6795 - accuracy: 0.5792 - auc: 0.5913 - val_loss: 0.6818 - val_accuracy: 0.5628 - val_auc: 0.5884 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6787 - accuracy: 0.5803 - auc: 0.5924 - val_loss: 0.6821 - val_accuracy: 0.5751 - val_auc: 0.5853 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 0.6788 - accuracy: 0.5805 - auc: 0.5903 - val_loss: 0.6820 - val_accuracy: 0.5612 - val_auc: 0.5893 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.6784 - accuracy: 0.5797 - auc: 0.5922 - val_loss: 0.6821 - val_accuracy: 0.5607 - val_auc: 0.5854 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "234/234 [==============================] - 5s 21ms/step - loss: 0.6784 - accuracy: 0.5809 - auc: 0.5923 - val_loss: 0.6815 - val_accuracy: 0.5660 - val_auc: 0.5865 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "234/234 [==============================] - 5s 20ms/step - loss: 0.6782 - accuracy: 0.5825 - auc: 0.5939 - val_loss: 0.6817 - val_accuracy: 0.5639 - val_auc: 0.5865 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "234/234 [==============================] - 3s 13ms/step - loss: 0.6783 - accuracy: 0.5804 - auc: 0.5927 - val_loss: 0.6838 - val_accuracy: 0.5623 - val_auc: 0.5868 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.6782 - accuracy: 0.5796 - auc: 0.5936 - val_loss: 0.6816 - val_accuracy: 0.5612 - val_auc: 0.5876 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.6777 - accuracy: 0.5800 - auc: 0.5966 - val_loss: 0.6816 - val_accuracy: 0.5612 - val_auc: 0.5861 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6776 - accuracy: 0.5792 - auc: 0.5964 - val_loss: 0.6817 - val_accuracy: 0.5617 - val_auc: 0.5872 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.6776 - accuracy: 0.5797 - auc: 0.5963 - val_loss: 0.6817 - val_accuracy: 0.5617 - val_auc: 0.5892 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.6776 - accuracy: 0.5804 - auc: 0.5960 - val_loss: 0.6817 - val_accuracy: 0.5612 - val_auc: 0.5866 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "234/234 [==============================] - 3s 11ms/step - loss: 0.6776 - accuracy: 0.5801 - auc: 0.5962 - val_loss: 0.6816 - val_accuracy: 0.5612 - val_auc: 0.5869 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.6775 - accuracy: 0.5784 - auc: 0.5959 - val_loss: 0.6816 - val_accuracy: 0.5612 - val_auc: 0.5873 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6775 - accuracy: 0.5793 - auc: 0.5962 - val_loss: 0.6815 - val_accuracy: 0.5628 - val_auc: 0.5872 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.6776 - accuracy: 0.5785 - auc: 0.5962 - val_loss: 0.6816 - val_accuracy: 0.5623 - val_auc: 0.5870 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.6775 - accuracy: 0.5788 - auc: 0.5966 - val_loss: 0.6816 - val_accuracy: 0.5612 - val_auc: 0.5865 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.6775 - accuracy: 0.5799 - auc: 0.5979 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5867 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6774 - accuracy: 0.5793 - auc: 0.5979 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5868 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "234/234 [==============================] - 3s 12ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5982 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5868 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6774 - accuracy: 0.5788 - auc: 0.5978 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5865 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5979 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5863 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6774 - accuracy: 0.5791 - auc: 0.5976 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5866 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "234/234 [==============================] - 3s 11ms/step - loss: 0.6774 - accuracy: 0.5793 - auc: 0.5980 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5870 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6774 - accuracy: 0.5788 - auc: 0.5977 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5869 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5978 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5870 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6774 - accuracy: 0.5791 - auc: 0.5981 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5866 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.6774 - accuracy: 0.5789 - auc: 0.5978 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5866 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5979 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5866 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6774 - accuracy: 0.5793 - auc: 0.5980 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5866 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5980 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5866 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6774 - accuracy: 0.5793 - auc: 0.5981 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5866 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "234/234 [==============================] - 3s 14ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5980 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5865 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.6774 - accuracy: 0.5791 - auc: 0.5980 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5865 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5980 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5865 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "234/234 [==============================] - 3s 11ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5981 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5865 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "234/234 [==============================] - 4s 15ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5980 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5865 - lr: 1.0000e-06\n",
      "Epoch 43/50\n",
      "234/234 [==============================] - 3s 11ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5979 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5865 - lr: 1.0000e-06\n",
      "Epoch 44/50\n",
      "234/234 [==============================] - 3s 11ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5979 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5865 - lr: 1.0000e-07\n",
      "Epoch 45/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5980 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5865 - lr: 1.0000e-07\n",
      "Epoch 46/50\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5980 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5865 - lr: 1.0000e-07\n",
      "Epoch 47/50\n",
      "234/234 [==============================] - 3s 11ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5980 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5865 - lr: 1.0000e-07\n",
      "Epoch 48/50\n",
      "234/234 [==============================] - 3s 13ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5980 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5865 - lr: 1.0000e-07\n",
      "Epoch 49/50\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5980 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5865 - lr: 1.0000e-07\n",
      "Epoch 50/50\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.6774 - accuracy: 0.5792 - auc: 0.5980 - val_loss: 0.6815 - val_accuracy: 0.5623 - val_auc: 0.5865 - lr: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(X_train.shape[1]))\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model=tf.keras.Model(inputs,outputs)\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy',tf.keras.metrics.AUC(name='auc')]\n",
    "             )\n",
    "batch_size=32\n",
    "epochs=50\n",
    "history=model.fit(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            validation_split=0.2,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=[tf.keras.callbacks.ReduceLROnPlateau()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 1s 5ms/step - loss: 0.6754 - accuracy: 0.5875 - auc: 0.6054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6753879189491272, 0.5874530076980591, 0.6054176092147827]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31806/295032384.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_pred = np.array(y_pred >=0.5, dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array(y_test)\n",
    "\n",
    "y_pred = np.squeeze(model.predict(x_test))\n",
    "y_pred = np.array(y_pred >=0.5, dtype=np.int)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5874530211043654"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracyKeras=accuracy_score(y_true, y_pred)\n",
    "accuracyKeras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
